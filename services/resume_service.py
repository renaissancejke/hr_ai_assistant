from __future__ import annotations

import datetime as dt
import re
from pathlib import Path
from typing import Any

from aiogram import Bot
from aiogram.types import File, FSInputFile

from bot.handlers.resume import ALLOWED_EXT, analyse_resume, extract_text
from settings.config import setup
from .vacancy_service import VacancyService
from .errors import InvalidResumeError


class ResumeService:

    THANKS_IMG = Path("data/static/thanks.png")

    @staticmethod
    def _ts() -> str:
        return dt.datetime.utcnow().strftime("%Y%m%dT%H%M%S")

    @classmethod
    async def _save_document(cls, bot: Bot, tg_file: File, ext: str) -> Path:
        target = Path(setup.data_dir) / f"{cls._ts()}_{tg_file.file_unique_id}{ext}"
        await bot.download(tg_file, destination=target)
        return target

    @staticmethod
    def _humanize_missing(val: Any) -> str:
        if not val:
            return "–∫–ª—é—á–µ–≤—ã—Ö –Ω–∞–≤—ã–∫–∞—Ö"
        if isinstance(val, str):
            return val.strip().rstrip(".;,")
        if isinstance(val, (list, tuple)):
            return ", ".join(map(str, val[:3])).rstrip(".;,")
        return str(val).rstrip(".;,")

    @staticmethod
    def _looks_like_resume(text: str) -> bool:
        """–ø—Ä–æ–≤–µ—Ä–∫–∞, —á—Ç–æ –ø—Ä–∏—Å–ª–∞–Ω –Ω–µ –ø—É—Å—Ç–æ–π –ª–∏—Å—Ç."""
        if len(text) < 150:
            return False
        words = text.split()
        if len(words) < 10:
            return False
        url_tokens = sum(bool(re.match(r"https?://", w)) for w in words)
        return url_tokens / len(words) <= 0.5

    @classmethod
    async def evaluate(
        cls,
        bot: Bot,
        tg_file: File,
        vacancy_name: str,
        ext: str,
        telegram_user_id: int,
    ) -> dict:
        if ext not in ALLOWED_EXT:
            raise ValueError("unsupported")

        file_path = await cls._save_document(bot, tg_file, ext)

        resume_text = extract_text(str(file_path))

        if not cls._looks_like_resume(resume_text):
            raise InvalidResumeError("–§–∞–π–ª –Ω–µ –ø–æ—Ö–æ–∂ –Ω–∞ —Ä–µ–∑—é–º–µ")

        vacancy_text = VacancyService.get(vacancy_name)
        meta = await analyse_resume(resume_text, vacancy_text)
        meta["file_path"] = str(file_path)
        return meta

    @classmethod
    def build_hr_caption(cls, vacancy: str, meta: dict, username: str | None) -> str:
        q = meta["interview_questions"]
        return (
            f"#{vacancy.replace(' ', '_')}\n"
            f"–ö–∞–Ω–¥–∏–¥–∞—Ç –ø–æ–¥—Ö–æ–¥–∏—Ç –Ω–∞ {meta['rating']:.0f}%\n\n"
            f"üí™ –°–∏–ª—å–Ω—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã: {meta['strong']}\n"
            f"üìâ –°–ª–∞–±—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã: {meta['weak']}\n"
            f"üîó –†–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–π –æ–ø—ã—Ç: {meta['matched_experience']}\n"
            f"üö´ –ù–µ —Ö–≤–∞—Ç–∞–µ—Ç –æ–ø—ã—Ç–∞: {cls._humanize_missing(meta.get('missing_experience'))}\n"
            f"üíß ¬´–í–æ–¥–∞¬ª: {meta['water']}\n"
            f"‚ö†Ô∏è –ù–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è / –ø–æ–¥–æ–∑—Ä–µ–Ω–∏—è: "
            f"{meta['mismatches'] or meta['suspicious']}\n\n"
            f"‚ùì –í–æ–ø—Ä–æ—Å—ã –¥–ª—è —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏—è:\n"
            f"‚Ä¢ {q[0]}\n‚Ä¢ {q[1]}\n‚Ä¢ {q[2]}\n\n"
            f"üì± –ö–æ–Ω—Ç–∞–∫—Ç: @{username or '‚Äî'}"
        )

    @classmethod
    def thanks_photo(cls) -> FSInputFile | None:
        return FSInputFile(cls.THANKS_IMG) if cls.THANKS_IMG.exists() else None
